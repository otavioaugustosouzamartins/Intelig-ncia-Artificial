{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nco_cm8gs_9U"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "The advancement of Artificial Intelligence (AI) has revolutionized several areas, especially in the field of supervised learning, where models are trained to make predictions and classifications based on labeled data. In this activity, we explore the impact and importance of different AI techniques in solving complex problems.\n",
        "\n",
        "Using the Wisconsin Breast Cancer database, a crucial problem in the medical field, we explored three different AI techniques: KNN (K-Nearest Neighbors), RNA MLP (Artificial Neural Networks - Multi-Layer Perceptron) and Random Forest ( Random Forest). Each technique was applied using 15 hyperparameter variations, totaling 90 different models. Furthermore, each training set was divided into two disjoint subsets to evaluate the stability of the models.\n",
        "\n",
        "To ensure robustness, each model was trained and evaluated 100 times without fixing a random seed, averaging its performance metrics. This approach allowed us to not only compare the effectiveness of techniques, but also identify which hyperparameter settings and training splits resulted in the best results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmNc78hSol55"
      },
      "source": [
        "# Database Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BBpQ_1eLXKGQ"
      },
      "outputs": [],
      "source": [
        "#--------------------------------------------------\n",
        "# Important Python libraries needed for the experiment\n",
        "# Matrix manipulation, mathematics and graphical visualization\n",
        "#--------------------------------------------------\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "#--------------------------------------------------\n",
        "# Data processing\n",
        "#--------------------------------------------------\n",
        "from sklearn.model_selection import train_test_split\n",
        "#--------------------------------------------------\n",
        "# Loading the smart model and performance metrics\n",
        "#--------------------------------------------------\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "#--------------------------------------------------\n",
        "# Loading performance metrics\n",
        "#--------------------------------------------------\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "#--------------------------------------------------\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "09Uy62sDXLQd",
        "outputId": "3227acc3-31b0-4cb0-81b1-9bc864aa0d68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Descriptive statistics of normalized variables:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>x17</th>\n",
              "      <td>569.0</td>\n",
              "      <td>0.080540</td>\n",
              "      <td>0.076227</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.038106</td>\n",
              "      <td>0.065379</td>\n",
              "      <td>0.106187</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>x26</th>\n",
              "      <td>569.0</td>\n",
              "      <td>0.240326</td>\n",
              "      <td>0.148711</td>\n",
              "      <td>0.025794</td>\n",
              "      <td>0.139130</td>\n",
              "      <td>0.200284</td>\n",
              "      <td>0.320510</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>x16</th>\n",
              "      <td>569.0</td>\n",
              "      <td>0.188169</td>\n",
              "      <td>0.132261</td>\n",
              "      <td>0.016632</td>\n",
              "      <td>0.096603</td>\n",
              "      <td>0.151034</td>\n",
              "      <td>0.239660</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>x25</th>\n",
              "      <td>569.0</td>\n",
              "      <td>0.594648</td>\n",
              "      <td>0.102572</td>\n",
              "      <td>0.319721</td>\n",
              "      <td>0.523810</td>\n",
              "      <td>0.589847</td>\n",
              "      <td>0.655885</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>x15</th>\n",
              "      <td>569.0</td>\n",
              "      <td>0.226180</td>\n",
              "      <td>0.096451</td>\n",
              "      <td>0.055027</td>\n",
              "      <td>0.166046</td>\n",
              "      <td>0.204947</td>\n",
              "      <td>0.261677</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>x19</th>\n",
              "      <td>569.0</td>\n",
              "      <td>0.260194</td>\n",
              "      <td>0.104704</td>\n",
              "      <td>0.099835</td>\n",
              "      <td>0.192020</td>\n",
              "      <td>0.237239</td>\n",
              "      <td>0.297403</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>x24</th>\n",
              "      <td>569.0</td>\n",
              "      <td>0.207001</td>\n",
              "      <td>0.133840</td>\n",
              "      <td>0.043535</td>\n",
              "      <td>0.121133</td>\n",
              "      <td>0.161378</td>\n",
              "      <td>0.254819</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>x10</th>\n",
              "      <td>569.0</td>\n",
              "      <td>0.644475</td>\n",
              "      <td>0.072459</td>\n",
              "      <td>0.512726</td>\n",
              "      <td>0.592159</td>\n",
              "      <td>0.631568</td>\n",
              "      <td>0.678571</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>x2</th>\n",
              "      <td>569.0</td>\n",
              "      <td>0.491081</td>\n",
              "      <td>0.109497</td>\n",
              "      <td>0.247200</td>\n",
              "      <td>0.411660</td>\n",
              "      <td>0.479633</td>\n",
              "      <td>0.554990</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>x30</th>\n",
              "      <td>569.0</td>\n",
              "      <td>0.404558</td>\n",
              "      <td>0.087042</td>\n",
              "      <td>0.265253</td>\n",
              "      <td>0.344386</td>\n",
              "      <td>0.385735</td>\n",
              "      <td>0.443759</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>x23</th>\n",
              "      <td>569.0</td>\n",
              "      <td>0.426995</td>\n",
              "      <td>0.133768</td>\n",
              "      <td>0.200677</td>\n",
              "      <td>0.334833</td>\n",
              "      <td>0.388774</td>\n",
              "      <td>0.499204</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>x29</th>\n",
              "      <td>569.0</td>\n",
              "      <td>0.436992</td>\n",
              "      <td>0.093202</td>\n",
              "      <td>0.235764</td>\n",
              "      <td>0.377222</td>\n",
              "      <td>0.425128</td>\n",
              "      <td>0.478909</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>x9</th>\n",
              "      <td>569.0</td>\n",
              "      <td>0.595927</td>\n",
              "      <td>0.090179</td>\n",
              "      <td>0.348684</td>\n",
              "      <td>0.532566</td>\n",
              "      <td>0.589474</td>\n",
              "      <td>0.643750</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>x11</th>\n",
              "      <td>569.0</td>\n",
              "      <td>0.141028</td>\n",
              "      <td>0.096524</td>\n",
              "      <td>0.038810</td>\n",
              "      <td>0.080891</td>\n",
              "      <td>0.112844</td>\n",
              "      <td>0.166690</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>x1</th>\n",
              "      <td>569.0</td>\n",
              "      <td>0.502572</td>\n",
              "      <td>0.125366</td>\n",
              "      <td>0.248346</td>\n",
              "      <td>0.416222</td>\n",
              "      <td>0.475631</td>\n",
              "      <td>0.561366</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>x6</th>\n",
              "      <td>569.0</td>\n",
              "      <td>0.302087</td>\n",
              "      <td>0.152903</td>\n",
              "      <td>0.056109</td>\n",
              "      <td>0.187956</td>\n",
              "      <td>0.268182</td>\n",
              "      <td>0.377533</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>x13</th>\n",
              "      <td>569.0</td>\n",
              "      <td>0.130394</td>\n",
              "      <td>0.091986</td>\n",
              "      <td>0.034440</td>\n",
              "      <td>0.073066</td>\n",
              "      <td>0.104049</td>\n",
              "      <td>0.152730</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>x7</th>\n",
              "      <td>569.0</td>\n",
              "      <td>0.208058</td>\n",
              "      <td>0.186785</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.069260</td>\n",
              "      <td>0.144189</td>\n",
              "      <td>0.306232</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>x27</th>\n",
              "      <td>569.0</td>\n",
              "      <td>0.217403</td>\n",
              "      <td>0.166633</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.091454</td>\n",
              "      <td>0.181070</td>\n",
              "      <td>0.305831</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>x22</th>\n",
              "      <td>569.0</td>\n",
              "      <td>0.518313</td>\n",
              "      <td>0.124067</td>\n",
              "      <td>0.242632</td>\n",
              "      <td>0.425515</td>\n",
              "      <td>0.512919</td>\n",
              "      <td>0.599919</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>x8</th>\n",
              "      <td>569.0</td>\n",
              "      <td>0.243137</td>\n",
              "      <td>0.192857</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.100944</td>\n",
              "      <td>0.166501</td>\n",
              "      <td>0.367793</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>x5</th>\n",
              "      <td>569.0</td>\n",
              "      <td>0.589720</td>\n",
              "      <td>0.086072</td>\n",
              "      <td>0.322093</td>\n",
              "      <td>0.528580</td>\n",
              "      <td>0.586720</td>\n",
              "      <td>0.644431</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>x20</th>\n",
              "      <td>569.0</td>\n",
              "      <td>0.127175</td>\n",
              "      <td>0.088675</td>\n",
              "      <td>0.029987</td>\n",
              "      <td>0.075335</td>\n",
              "      <td>0.106803</td>\n",
              "      <td>0.152748</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>x21</th>\n",
              "      <td>569.0</td>\n",
              "      <td>0.451420</td>\n",
              "      <td>0.134108</td>\n",
              "      <td>0.220033</td>\n",
              "      <td>0.360988</td>\n",
              "      <td>0.415372</td>\n",
              "      <td>0.521365</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>x14</th>\n",
              "      <td>569.0</td>\n",
              "      <td>0.074395</td>\n",
              "      <td>0.083901</td>\n",
              "      <td>0.012545</td>\n",
              "      <td>0.032921</td>\n",
              "      <td>0.045242</td>\n",
              "      <td>0.083346</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>x4</th>\n",
              "      <td>569.0</td>\n",
              "      <td>0.261851</td>\n",
              "      <td>0.140709</td>\n",
              "      <td>0.057377</td>\n",
              "      <td>0.168053</td>\n",
              "      <td>0.220352</td>\n",
              "      <td>0.312955</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>x18</th>\n",
              "      <td>569.0</td>\n",
              "      <td>0.223454</td>\n",
              "      <td>0.116884</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.144686</td>\n",
              "      <td>0.207047</td>\n",
              "      <td>0.278651</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>x3</th>\n",
              "      <td>569.0</td>\n",
              "      <td>0.487899</td>\n",
              "      <td>0.128907</td>\n",
              "      <td>0.232308</td>\n",
              "      <td>0.398780</td>\n",
              "      <td>0.457507</td>\n",
              "      <td>0.552255</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>x12</th>\n",
              "      <td>569.0</td>\n",
              "      <td>0.249100</td>\n",
              "      <td>0.112927</td>\n",
              "      <td>0.073736</td>\n",
              "      <td>0.170706</td>\n",
              "      <td>0.226817</td>\n",
              "      <td>0.301740</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>x28</th>\n",
              "      <td>569.0</td>\n",
              "      <td>0.393836</td>\n",
              "      <td>0.225884</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.223127</td>\n",
              "      <td>0.343402</td>\n",
              "      <td>0.554639</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     count      mean       std       min       25%       50%       75%  max\n",
              "x17  569.0  0.080540  0.076227  0.000000  0.038106  0.065379  0.106187  1.0\n",
              "x26  569.0  0.240326  0.148711  0.025794  0.139130  0.200284  0.320510  1.0\n",
              "x16  569.0  0.188169  0.132261  0.016632  0.096603  0.151034  0.239660  1.0\n",
              "x25  569.0  0.594648  0.102572  0.319721  0.523810  0.589847  0.655885  1.0\n",
              "x15  569.0  0.226180  0.096451  0.055027  0.166046  0.204947  0.261677  1.0\n",
              "x19  569.0  0.260194  0.104704  0.099835  0.192020  0.237239  0.297403  1.0\n",
              "x24  569.0  0.207001  0.133840  0.043535  0.121133  0.161378  0.254819  1.0\n",
              "x10  569.0  0.644475  0.072459  0.512726  0.592159  0.631568  0.678571  1.0\n",
              "x2   569.0  0.491081  0.109497  0.247200  0.411660  0.479633  0.554990  1.0\n",
              "x30  569.0  0.404558  0.087042  0.265253  0.344386  0.385735  0.443759  1.0\n",
              "x23  569.0  0.426995  0.133768  0.200677  0.334833  0.388774  0.499204  1.0\n",
              "x29  569.0  0.436992  0.093202  0.235764  0.377222  0.425128  0.478909  1.0\n",
              "x9   569.0  0.595927  0.090179  0.348684  0.532566  0.589474  0.643750  1.0\n",
              "x11  569.0  0.141028  0.096524  0.038810  0.080891  0.112844  0.166690  1.0\n",
              "x1   569.0  0.502572  0.125366  0.248346  0.416222  0.475631  0.561366  1.0\n",
              "x6   569.0  0.302087  0.152903  0.056109  0.187956  0.268182  0.377533  1.0\n",
              "x13  569.0  0.130394  0.091986  0.034440  0.073066  0.104049  0.152730  1.0\n",
              "x7   569.0  0.208058  0.186785  0.000000  0.069260  0.144189  0.306232  1.0\n",
              "x27  569.0  0.217403  0.166633  0.000000  0.091454  0.181070  0.305831  1.0\n",
              "x22  569.0  0.518313  0.124067  0.242632  0.425515  0.512919  0.599919  1.0\n",
              "x8   569.0  0.243137  0.192857  0.000000  0.100944  0.166501  0.367793  1.0\n",
              "x5   569.0  0.589720  0.086072  0.322093  0.528580  0.586720  0.644431  1.0\n",
              "x20  569.0  0.127175  0.088675  0.029987  0.075335  0.106803  0.152748  1.0\n",
              "x21  569.0  0.451420  0.134108  0.220033  0.360988  0.415372  0.521365  1.0\n",
              "x14  569.0  0.074395  0.083901  0.012545  0.032921  0.045242  0.083346  1.0\n",
              "x4   569.0  0.261851  0.140709  0.057377  0.168053  0.220352  0.312955  1.0\n",
              "x18  569.0  0.223454  0.116884  0.000000  0.144686  0.207047  0.278651  1.0\n",
              "x3   569.0  0.487899  0.128907  0.232308  0.398780  0.457507  0.552255  1.0\n",
              "x12  569.0  0.249100  0.112927  0.073736  0.170706  0.226817  0.301740  1.0\n",
              "x28  569.0  0.393836  0.225884  0.000000  0.223127  0.343402  0.554639  1.0"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "column_names = 'ID,Target,x1,x2,x3,x4,x5,x6,x7,x8,x9,x10,x11,x12,x13,x14,x15,x16,x17,x18,x19,x20,x21,x22,x23,x24,x25,x26,x27,x28,x29,x30'\n",
        "\n",
        "\n",
        "\n",
        "# Reading data\n",
        "df = pd.read_csv('wdbc.data', names=column_names.split(','))\n",
        "\n",
        "df.drop('ID', axis=1, inplace=True)\n",
        "df['Target'] = df['Target'].map({'M': 1, 'B': 0})\n",
        "\n",
        "# Data normalization\n",
        "target_column = ['Target']\n",
        "predictors = list(set(list(df.columns))-set(target_column))\n",
        "df[predictors] = df[predictors]/df[predictors].max()\n",
        "\n",
        "\n",
        "print(\"Descriptive statistics of normalized variables:\")\n",
        "df[predictors].describe().transpose()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzsFZ0njXccQ",
        "outputId": "6d1d733b-8c4d-4800-eb0a-02ec40ce4e0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.13568182 0.62911153 0.36218612 ... 0.65145889 0.18532242 0.91202749]\n",
            " [0.0469697  0.17637051 0.09660266 ... 0.70503979 0.15023541 0.63917526]\n",
            " [0.09676768 0.40122873 0.29586411 ... 0.68965517 0.16108495 0.83505155]\n",
            " ...\n",
            " [0.11944444 0.29243856 0.27555391 ... 0.57453581 0.22006141 0.48728522]\n",
            " [0.17972222 0.8205104  0.45480059 ... 0.74323607 0.32650972 0.91065292]\n",
            " [0.         0.06090737 0.03441654 ... 0.25421751 0.29232344 0.        ]]\n",
            "Training Set---Size: (398, 30)\n",
            "[[0.04494949 0.17240076 0.11757755 ... 0.46748011 0.15504606 0.20683849]\n",
            " [0.12517677 0.23922495 0.24150665 ... 0.45676393 0.23336745 0.30852234]\n",
            " [0.13328283 0.34357278 0.3872969  ... 0.52106101 0.30931423 0.38075601]\n",
            " ...\n",
            " [0.01218687 0.04759924 0.0274003  ... 0.47904509 0.14734903 0.11453608]\n",
            " [0.05517677 0.33724008 0.13227474 ... 0.48339523 0.19514841 0.62783505]\n",
            " [0.02699495 0.08376181 0.04503693 ... 0.40965517 0.32159672 0.25536082]]\n",
            "\n",
            "Test Set---Size: (171, 30)\n",
            "[[0.06820707 0.22476371 0.14113737 ... 0.43018568 0.21371546 0.34879725]\n",
            " [0.05729798 0.22079395 0.12200886 ... 0.65570292 0.16325486 0.61477663]\n",
            " [0.07103535 0.22627599 0.10960118 ... 0.53952255 0.16088025 0.52027491]\n",
            " ...\n",
            " [0.30227273 0.27882798 0.65051699 ... 0.34270557 0.46284545 0.34054983]\n",
            " [0.08777778 0.37485822 0.28478582 ... 0.48981432 0.31279427 0.52268041]\n",
            " [0.2060101  0.55283554 0.41299852 ... 0.45066313 0.09011259 0.53642612]]\n"
          ]
        }
      ],
      "source": [
        "entrada_X = df[predictors].values\n",
        "print(entrada_X)\n",
        "saidaDesejada_y = df[target_column].values\n",
        "\n",
        "#Applying the train_test_split function to divide the original set into 70% for training and 30% for testing.\n",
        "X_train, X_test, y_train, y_test = train_test_split(entrada_X, saidaDesejada_y, test_size=0.3, random_state=42) # 42 fixa\n",
        "print(f\"Training Set---Size: {X_train.shape}\")\n",
        "print(X_train);\n",
        "print(f\"\\nTest Set---Size: {X_test.shape}\")\n",
        "print(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ll_DECXin-wY"
      },
      "source": [
        "#Treinamento e teste dos modelos\n",
        "Abaixo, criamos uma função genérica para treinar os três modelos utilizados no desenvolvimento desse trabalho."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "RjBsPQX7Xe0G"
      },
      "outputs": [],
      "source": [
        "def training_models(model, parameters, X_train, y_train, random_state=None):\n",
        "\n",
        "  metrics = []\n",
        "\n",
        "  for params in parameters:\n",
        "\n",
        "    # Splitting the training set into two disjoint subsets\n",
        "    X_train_1, X_train_2, y_train_1, y_train_2 = train_test_split(X_train, y_train, test_size=0.5, random_state=random_state)\n",
        "\n",
        "    y_train_1 = np.ravel(y_train_1)\n",
        "    y_train_2 = np.ravel(y_train_2)\n",
        "\n",
        "    #2 training subsets\n",
        "    conjunto_1 = (X_train_1, y_train_1)\n",
        "    conjunto_2 = (X_train_2, y_train_2)\n",
        "\n",
        "\n",
        "\n",
        "    for current_x_train, current_y_train in [conjunto_1, conjunto_2]:\n",
        "      accs = []\n",
        "      f1s = []\n",
        "      recs = []\n",
        "      precs = []\n",
        "      for _ in range(100):\n",
        "\n",
        "        #Performing model training\n",
        "        mod = model(**params) # The ** operator is used to unpack the 'params' dict and pass its elements as named arguments to the initialization of the 'model' object\n",
        "        mod.fit(current_x_train, current_y_train) # training the model\n",
        "        y_pred = mod.predict(X_test) # testing the model with the test dataset\n",
        "\n",
        "\n",
        "        current_acc = accuracy_score(y_test, y_pred)\n",
        "        current_f1 = f1_score(y_test, y_pred)\n",
        "        current_rec = recall_score(y_test, y_pred)\n",
        "        current_prec = precision_score(y_test, y_pred)\n",
        "\n",
        "\n",
        "        accs.append(current_acc)\n",
        "        f1s.append(current_f1)\n",
        "        recs.append(current_rec)\n",
        "        precs.append(current_prec)\n",
        "\n",
        "      metrics.append({\n",
        "          'params': params,\n",
        "          'accuracy': np.mean(accs),\n",
        "          'f1': np.mean(f1s),\n",
        "          'recall': np.mean(recs),\n",
        "          'precision': np.mean(precs)\n",
        "      })\n",
        "\n",
        "  return metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsb1EQKTw4tZ"
      },
      "source": [
        "# Auxiliary Functions\n",
        "Functions that assist in the code such as displaying metrics, graphs, calculating means, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "3SebC7HGvi-a"
      },
      "outputs": [],
      "source": [
        "def max_and_min_metrics(model_metrics, metric):\n",
        "  max1 = 0\n",
        "  max2 = 0\n",
        "  min1 = 1\n",
        "  min2 = 1\n",
        "\n",
        "  for i in range(0,30):\n",
        "    current = model_metrics[i][metric]\n",
        "    current_param = model_metrics[i]['params']\n",
        "\n",
        "    if i%2 == 0: # belongs to set 1\n",
        "      if current > max1:\n",
        "        max1 = current\n",
        "        param = current_param\n",
        "      elif current < min1:\n",
        "        min1 = current\n",
        "        param = current_param\n",
        "\n",
        "\n",
        "    else: # belongs to set 2\n",
        "      if current > max2:\n",
        "        max2 = current\n",
        "        param = current_param\n",
        "      elif current < min2:\n",
        "        min2 = current\n",
        "        param = current_param\n",
        "\n",
        "\n",
        "  return (\n",
        "      {'max': max1, 'min': min1, 'params': param},\n",
        "      {'max': max2, 'min': min2, 'params': param}\n",
        "  )\n",
        "\n",
        "\n",
        "\n",
        "def separate_by_parameter_and_metric(model_metrics, metrics, parameters):\n",
        "    separated_metrics = []\n",
        "    separated_params1 = []\n",
        "    separated_params2 = []\n",
        "    count = 0\n",
        "\n",
        "    for m in model_metrics:\n",
        "        if all(param in m['params'] and m['params'][param] == parameters[param] for param in parameters):\n",
        "            separated_metrics.append(m[metrics])\n",
        "            if count % 2 == 0:\n",
        "              separated_params1.append(m['params'])\n",
        "            else:\n",
        "              separated_params2.append(m['params'])\n",
        "            count = count + 1\n",
        "\n",
        "    length = len(separated_metrics) // 2\n",
        "\n",
        "    return (\n",
        "        {f'{metrics}': separated_metrics[:length], 'params': separated_params1},\n",
        "        {f'{metrics}': separated_metrics[length:], 'params': separated_params2}\n",
        "    )\n",
        "\n",
        "def print_metrics(model, metrics):\n",
        "  print(f\"Model: {model}\")\n",
        "\n",
        "  print(\"\\n================= First training subset metrics =================\\n\")\n",
        "  for i in range(0,len(metrics)):\n",
        "    if i%2 == 0:\n",
        "      print(f\"\\nParameters used:   {metrics[i]['params']}\")\n",
        "      print(f\"Accuracy:   {metrics[i]['accuracy']}\")\n",
        "      print(f\"F1 Score:   {metrics[i]['f1']}\")\n",
        "      print(f\"Recall:     {metrics[i]['recall']}\")\n",
        "      print(f\"Precision:  {metrics[i]['precision']}\")\n",
        "\n",
        "  print(\"\\n================= Second training subset metrics =================\\n\")\n",
        "  for i in range(0,len(metrics)):\n",
        "    if i%2 != 0:\n",
        "      print(f\"\\nParameters used:   {metrics[i]['params']}\")\n",
        "      print(f\"Accuracy:   {metrics[i]['accuracy']}\")\n",
        "      print(f\"F1 Score:   {metrics[i]['f1']}\")\n",
        "      print(f\"Recall:     {metrics[i]['recall']}\")\n",
        "      print(f\"Precision:  {metrics[i]['precision']}\")\n",
        "\n",
        "def specific_metric_mean(model1, model2, metric):\n",
        "  met1 = []\n",
        "  met2 = []\n",
        "\n",
        "  for i in range(len(model1)):\n",
        "    current = model1[i]\n",
        "    met1.append(current[metric])\n",
        "\n",
        "  for i in range(len(model2)):\n",
        "    current = model2[i]\n",
        "    met2.append(current[metric])\n",
        "\n",
        "  return (np.mean(met1), np.mean(met2)) # mean of the specified metric in each set\n",
        "\n",
        "\n",
        "\n",
        "def metrics_mean(model_metrics): # returns the mean of measurements from both sets\n",
        "  acc1 = []\n",
        "  f1_score1 =[]\n",
        "  rec1 = []\n",
        "  prec1 = []\n",
        "\n",
        "  acc2 = []\n",
        "  f1_score2 =[]\n",
        "  rec2 = []\n",
        "  prec2 = []\n",
        "\n",
        "  for i in range(len(model_metrics)):\n",
        "    current = model_metrics[i]\n",
        "\n",
        "    if i%2 == 0:\n",
        "      acc1.append(current['accuracy'])\n",
        "      f1_score1.append(current['f1'])\n",
        "      rec1.append(current['recall'])\n",
        "      prec1.append(current['precision'])\n",
        "\n",
        "    else:\n",
        "      acc2.append(current['accuracy'])\n",
        "      f1_score2.append(current['f1'])\n",
        "      rec2.append(current['recall'])\n",
        "      prec2.append(current['precision'])\n",
        "\n",
        "  return (\n",
        "      [np.mean(acc1), np.mean(f1_score1), np.mean(rec1), np.mean(prec1)],\n",
        "      [np.mean(acc2), np.mean(f1_score2), np.mean(rec2), np.mean(prec2)]\n",
        "  )\n",
        "\n",
        "def bar_graph(model_metrics):\n",
        "\n",
        "  metrics = ['Accuracy', 'F1 Score', 'Recall', 'Precision']\n",
        "  [model1, model2] = metrics_mean(model_metrics)\n",
        "\n",
        "  bar_width = 0.25\n",
        "\n",
        "  r1 = np.arange(4)\n",
        "  r2 = [x + bar_width for x in r1]\n",
        "\n",
        "  # Creating the bar chart\n",
        "  plt.figure(figsize=(10, 6))\n",
        "  plt.bar(r1, model1, color='#9448BC', width=bar_width, edgecolor='grey', label='Model 1')\n",
        "  plt.bar(r2, model2, color='#480355', width=bar_width, edgecolor='grey', label='Model 2')\n",
        "\n",
        "  # Adding metric labels on the x-axis\n",
        "  plt.xlabel('Metrics', fontweight='bold')\n",
        "  plt.xticks([r + bar_width / 2 for r in range(4)], metrics)\n",
        "\n",
        "  ax = plt.gca()\n",
        "  for i, height in enumerate(model1):\n",
        "      ax.text(r1[i], height + 0.01, f'{height:.2f}', ha='center', va='bottom', fontsize=10)\n",
        "  for i, height in enumerate(model2):\n",
        "      ax.text(r2[i], height + 0.01, f'{height:.2f}', ha='center', va='bottom', fontsize=10)\n",
        "\n",
        "  plt.legend(loc='upper right', fontsize='small', title='Title', bbox_to_anchor=(1.15, 1))\n",
        "  plt.tight_layout()\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "\n",
        "def bar_graph_metric_and_parameter(model_metrics, metric, parameters):\n",
        "    model1, model2 = separate_by_parameter_and_metric(model_metrics, metric, parameters)\n",
        "\n",
        "    metrics1 = model1[metric]\n",
        "    metrics2 = model2[metric]\n",
        "    params = model1['params']\n",
        "\n",
        "\n",
        "\n",
        "    bar_width = 0.35\n",
        "\n",
        "    r1 = np.arange(len(metrics1))\n",
        "    r2 = [x + bar_width for x in np.arange(len(metrics2))]\n",
        "\n",
        "    plt.figure(figsize=(10, 6))  # Increase the size of the graph\n",
        "    plt.bar(r1, metrics1, color='#9448BC', width=bar_width, edgecolor='grey', label='Model 1')\n",
        "    plt.bar(r2, metrics2, color='#480355', width=bar_width, edgecolor='grey', label='Model 2')\n",
        "\n",
        "    # Adding metric labels on the x-axis\n",
        "    plt.xlabel(f\"{metric.capitalize()}\", fontweight='bold')\n",
        "\n",
        "    # Adjusting x-axis labels\n",
        "    labels = [str(param) for param in params]\n",
        "    plt.xticks([r + bar_width / 2 for r in range(len(labels))], labels, rotation=0, ha='center', fontsize=10)\n",
        "\n",
        "    # Adding metric values ​​above the bars\n",
        "    ax = plt.gca()\n",
        "    for i, height in enumerate(metrics1):\n",
        "        ax.text(r1[i], height + 0.01, f'{height:.2f}', ha='center', va='bottom')\n",
        "    for i, height in enumerate(metrics2):\n",
        "        ax.text(r2[i], height + 0.01, f'{height:.2f}', ha='center', va='bottom')\n",
        "\n",
        "    plt.legend(loc='upper right', fontsize='small', title='Sets', bbox_to_anchor=(1.15, 1))\n",
        "    plt.tight_layout()\n",
        "    plt.subplots_adjust(left=0.05, right=0.95, top=0.95, bottom=0.25)  # Ajustar o espaçamento ao redor do gráfico\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "def graph_max_min(model1, model2, metric):\n",
        "    maxs = [model1['max'], model2['max']]\n",
        "    mins = [model1['min'], model2['min']]\n",
        "    models = ['Model 1', 'Model 2']\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    largura_barra = 0.35\n",
        "    indice = range(2)  \n",
        "\n",
        "   \n",
        "    bar1 = ax.bar([i - largura_barra/2 for i in indice], maxs, largura_barra, label='Max', linewidth=20)\n",
        "    for i, v in enumerate(maxs):\n",
        "        ax.text(i - largura_barra/2, v + 0.01, f'{v:.2f}', ha='center', va='bottom')\n",
        "\n",
        "    bar2 = ax.bar([i + largura_barra/2 for i in indice], mins, largura_barra, label='Min', linewidth=2)\n",
        "    for i, v in enumerate(mins):\n",
        "        ax.text(i + largura_barra/2, v + 0.01, f'{v:.2f}', ha='center', va='bottom')\n",
        "\n",
        "\n",
        "    ax.margins(x=0.1, y=0.1)\n",
        "\n",
        "    ax.set_xlabel('Models')\n",
        "    ax.set_ylabel('Values')\n",
        "    ax.set_title(f'Max/Min {metric.capitalize()} of Two Models')\n",
        "    ax.set_xticks(indice)\n",
        "    ax.set_xticklabels(models)\n",
        "    ax.legend(loc='upper right', fontsize='small', title='title', bbox_to_anchor=(1.25, 1))\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "842l6SWDo3oA"
      },
      "source": [
        "# KNN (K-Nearest Neighbors)\n",
        "\n",
        "The KNN (K-Nearest Neighbors) algorithm is commonly used in supervised learning for classification and regression. It decides the class of a new example by calculating its distance to all training examples. The K closest examples are selected, and the class of the new example is determined by majority voting among these neighbors. Essentially, KNN relies on the similarity of data to make predictions, being simple to understand and implement, but sensitive to the choice of the K parameter and the appropriate treatment of the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NYFIhb76b007"
      },
      "outputs": [],
      "source": [
        "params = [{'n_neighbors': k, 'metric': metric} for k in [1, 3, 5, 7, 9] for metric in ['euclidean', 'manhattan', 'chebyshev']] # 15 parâmetros\n",
        "\n",
        "knn_metrics = training_models(KNeighborsClassifier, params, X_train, y_train)\n",
        "\n",
        "print_metrics(\"KNN\", knn_metrics)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NI9UNpPx6ZI"
      },
      "source": [
        "# Artificial Neural Networks (MLP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vt2WtZpLyE7E",
        "outputId": "cfee3130-f32d-47b4-c5ee-38c4b7afc6d8"
      },
      "outputs": [],
      "source": [
        "parametros_mlp = [{'hidden_layer_sizes': h, 'max_iter': m} for h in [50, 100, 150, 200, 250] for m in [200, 300, 400]] # 15 parameters\n",
        "\n",
        "mlp_metrics = training_models(MLPClassifier, parametros_mlp, X_train, y_train)\n",
        "\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "\n",
        "print_metrics(\"MLP\", mlp_metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOiB5z2wpsxm"
      },
      "source": [
        "# Random Forest\n",
        "\n",
        "\n",
        "The Random Forest algorithm is an advanced supervised learning technique that utilizes the combination of multiple decision trees to enhance the accuracy and robustness of the predictive model. During training, multiple trees are constructed using random samples from the dataset, with each tree using only a random subset of the features. This introduces diversity among the individual trees, reducing overfitting and improving the model's generalization ability. To predict the class in classification problems or the value in regression problems, Random Forest combines the predictions of all the trees through voting (for classification) or averaging (for regression), resulting in a more accurate and stable final estimate. This approach makes Random Forest effective for handling complex and non-linear data, while maintaining reasonable interpretability. However, proper parameter tuning is crucial to optimize its performance in different application contexts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZ6bMHNxp1iK"
      },
      "outputs": [],
      "source": [
        "parametros_rf = [{'n_estimators': n, 'max_depth': d} for n in [50, 100, 150, 200, 250] for d in [10, 20, 30]]\n",
        "\n",
        "rf_metrics = training_models(RandomForestClassifier, parametros_rf, X_train, y_train)\n",
        "\n",
        "print_metrics(\"Random Forest\", rf_metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juC3YP4qIMFI"
      },
      "source": [
        "For the dataset in this problem, which relates to breast cancer, recall should be considered the most important metric for measuring the effectiveness of the models. Recall is defined as: \n",
        "$${TP \\over TP+FN}$$\n",
        "\\\n",
        "Therefore, the model's effectiveness will be better the lower the number of false negatives. In the current scenario of a medical evaluation, it is crucial to have a low number of false-negative diagnoses, meaning that breast cancer is not detected in patients who actually have it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIaEcmoVODvp"
      },
      "source": [
        "## KNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "id": "MpOKEVg9KKsx",
        "outputId": "7468254a-422c-4b82-e4c7-a0669318feb3"
      },
      "outputs": [],
      "source": [
        "# Total average of metrics\n",
        "bar_graph(knn_metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fT7OFVSdLtCI",
        "outputId": "945b7fa3-9c13-4bc1-d77d-9a1d3664c2f6"
      },
      "outputs": [],
      "source": [
        "# Average of metrics for 1 neighbor\n",
        "distances = ['euclidean', 'manhattan', 'chebyshev']\n",
        "\n",
        "for d in distances:\n",
        "  bar_graph_metric_and_parameter(knn_metrics, 'accuracy', {'n_neighbors': 1, 'metric': d})\n",
        "  bar_graph_metric_and_parameter(knn_metrics, 'f1', {'n_neighbors': 1, 'metric': d})\n",
        "  bar_graph_metric_and_parameter(knn_metrics, 'recall', {'n_neighbors': 1, 'metric': d})\n",
        "  bar_graph_metric_and_parameter(knn_metrics, 'precision', {'n_neighbors': 1, 'metric': d})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KGEHLJ0sMN7T",
        "outputId": "dfc3f209-f1d7-4dec-a169-dd791c1a70fb"
      },
      "outputs": [],
      "source": [
        "# Average of metrics for 3 neighbors\n",
        "distances = ['euclidean', 'manhattan', 'chebyshev']\n",
        "\n",
        "for d in distances:\n",
        "  bar_graph_metric_and_parameter(knn_metrics, 'accuracy', {'n_neighbors': 3, 'metric': d})\n",
        "  bar_graph_metric_and_parameter(knn_metrics, 'f1', {'n_neighbors': 3, 'metric': d})\n",
        "  bar_graph_metric_and_parameter(knn_metrics, 'recall', {'n_neighbors': 3, 'metric': d})\n",
        "  bar_graph_metric_and_parameter(knn_metrics, 'precision', {'n_neighbors': 3, 'metric': d})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zprXclbOMfIZ",
        "outputId": "a5ae63da-8315-45a5-8dfe-c99088b94305"
      },
      "outputs": [],
      "source": [
        "# Average of metrics for 5 neighbors\n",
        "distancias = ['euclidean', 'manhattan', 'chebyshev']\n",
        "\n",
        "for d in distancias:\n",
        "  bar_graph_metric_and_parameter(knn_metrics, 'accuracy', {'n_neighbors': 5, 'metric': d})\n",
        "  bar_graph_metric_and_parameter(knn_metrics, 'f1', {'n_neighbors': 5, 'metric': d})\n",
        "  bar_graph_metric_and_parameter(knn_metrics, 'recall', {'n_neighbors': 5, 'metric': d})\n",
        "  bar_graph_metric_and_parameter(knn_metrics, 'precision', {'n_neighbors': 5, 'metric': d})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XYal6TLsMvLH",
        "outputId": "78d56d12-2888-4f1a-e53e-d29c799a4801"
      },
      "outputs": [],
      "source": [
        "# Average of metrics for 7 neighbors\n",
        "distancias = ['euclidean', 'manhattan', 'chebyshev']\n",
        "\n",
        "for d in distancias:\n",
        "  bar_graph_metric_and_parameter(knn_metrics, 'accuracy', {'n_neighbors': 7, 'metric': d})\n",
        "  bar_graph_metric_and_parameter(knn_metrics, 'f1', {'n_neighbors': 7, 'metric': d})\n",
        "  bar_graph_metric_and_parameter(knn_metrics, 'recall', {'n_neighbors': 7, 'metric': d})\n",
        "  bar_graph_metric_and_parameter(knn_metrics, 'precision', {'n_neighbors': 7, 'metric': d})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "L1qMo5NRLH8s",
        "outputId": "df111335-bc38-47f9-f613-7f44d57f811f"
      },
      "outputs": [],
      "source": [
        "# Average of metrics for 9 neighbors\n",
        "distancias = ['euclidean', 'manhattan', 'chebyshev']\n",
        "\n",
        "for d in distancias:\n",
        "  bar_graph_metric_and_parameter(knn_metrics, 'accuracy', {'n_neighbors': 9, 'metric': d})\n",
        "  bar_graph_metric_and_parameter(knn_metrics, 'f1', {'n_neighbors': 9, 'metric': d})\n",
        "  bar_graph_metric_and_parameter(knn_metrics, 'recall', {'n_neighbors': 9, 'metric': d})\n",
        "  bar_graph_metric_and_parameter(knn_metrics, 'precision', {'n_neighbors': 9, 'metric': d})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Z6-OgLHxiZr4",
        "outputId": "d35cd515-034f-4904-9701-ca2659ee9eb2"
      },
      "outputs": [],
      "source": [
        "# Max and Min of all metrics\n",
        "metrics = ['recall','accuracy', 'f1', 'precision']\n",
        "\n",
        "for m in metrics:\n",
        "  (mod1,mod2) = max_and_min_metrics(knn_metrics,m)\n",
        "  graph_max_min(mod1,mod2,m)\n",
        "  print() # \\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTGMgJdqPTqI"
      },
      "source": [
        "### KNN Conclusion\n",
        "The KNN algorithm proved to be more effective using Euclidean distance, regardless of the variation in the number of neighbors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSIcLlvtNZvL"
      },
      "source": [
        "## MLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "id": "QuJJ-eNOTrN_",
        "outputId": "23199388-6700-439e-cdeb-1b317ed4e2e3"
      },
      "outputs": [],
      "source": [
        "# Total average of metrics\n",
        "bar_graph(mlp_metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IIxsy2-xT3a6",
        "outputId": "c7eb727b-7140-4253-cef6-8c5ad5379da7"
      },
      "outputs": [],
      "source": [
        "# Average of metrics with parameter variation\n",
        "\n",
        "hidden_layer_sizes = [50, 100, 150, 200, 250]\n",
        "max_iters = [200, 300, 400]\n",
        "\n",
        "for h in hidden_layer_sizes:\n",
        "  for m in max_iters:\n",
        "     bar_graph_metric_and_parameter(mlp_metrics, 'accuracy', {'hidden_layer_sizes': h,'max_iter': m})\n",
        "     bar_graph_metric_and_parameter(mlp_metrics, 'f1', {'hidden_layer_sizes': h,'max_iter': m})\n",
        "     bar_graph_metric_and_parameter(mlp_metrics, 'recall', {'hidden_layer_sizes': h,'max_iter': m})\n",
        "     bar_graph_metric_and_parameter(mlp_metrics, 'precision', {'hidden_layer_sizes': h,'max_iter': m})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "q94-L4zU48xa",
        "outputId": "b2b05842-6dfa-4afd-8c5a-ffcd9bbe0a27"
      },
      "outputs": [],
      "source": [
        "# Max and Min of all metrics\n",
        "metrics = ['recall', 'f1', 'precision', 'accuracy']\n",
        "\n",
        "for m in metrics:\n",
        "  (mod1,mod2) = max_and_min_metrics(mlp_metrics,m)\n",
        "  graph_max_min(mod1,mod2,m)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtRpufhlVbTk"
      },
      "source": [
        "### MLP conclusion\n",
        "For the MLP, we have that, for model 1 and model 2, the maximum and minimum values ​​were better in the \"Accuracy\" metric, being (0.98;0.95) for model 1 and (0.98 ;0.94) for model 2, in the parameters hidden_layer_sizes: 250 and max_iter: 400"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPmgnOFsNjED"
      },
      "source": [
        "## Random Forest\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "EdRWfK7mUkuA",
        "outputId": "de543c17-1a55-4cc8-ad98-35835ca3cec3"
      },
      "outputs": [],
      "source": [
        "# Total average of metrics\n",
        "bar_graph(rf_metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "n6sE5cvqUzot",
        "outputId": "8875753a-8eb9-4890-c7e9-56f3827b8932"
      },
      "outputs": [],
      "source": [
        "# Average of metrics with parameter variation\n",
        "n_estimators = [50, 100, 150, 200, 250]\n",
        "max_depths = [10, 20, 30]\n",
        "\n",
        "for n in n_estimators:\n",
        "  for m in max_depths:\n",
        "   bar_graph_metric_and_parameter(rf_metrics, 'accuracy', {'n_estimators': n, 'max_depth': m})\n",
        "   bar_graph_metric_and_parameter(rf_metrics, 'f1',  {'n_estimators': n, 'max_depth': m})\n",
        "   bar_graph_metric_and_parameter(rf_metrics, 'recall',  {'n_estimators': n, 'max_depth': m})\n",
        "   bar_graph_metric_and_parameter(rf_metrics, 'precision',  {'n_estimators': n, 'max_depth': m})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "k8caWLbTVPOM",
        "outputId": "445f7573-befa-493e-93c5-d59d54894503"
      },
      "outputs": [],
      "source": [
        "# Max and Min of all metrics\n",
        "metrics = ['recall', 'f1', 'precision', 'accuracy']\n",
        "\n",
        "for m in metrics:\n",
        "  (mod1,mod2) = max_and_min_metrics(rf_metrics,m)\n",
        "  graph_max_min(mod1,mod2,m)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FL8F2ifVXLa"
      },
      "source": [
        "### Random Forest Conclusion\n",
        "For Random Forest, we have that, for the maximum and minimum values ​​that were best analyzed, they were for the Accuracy metric, in the parameters n_estimators:250 and max_depth: 20, with values ​​(0.97;0.96) for model 1 and (0.97;0.95) for model 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrnfaS25AT63"
      },
      "source": [
        "# Conclusion\n",
        "\n",
        "Using a variety of models in supervised learning problems is crucial. Each algorithm has its advantages and limitations, and the application of different models, such as K-NN, Decision Tree and Random Forest, can provide a more complete and accurate understanding of the problem, especially in the detection of breast cancer, assisting in more accurate diagnoses. fast and accurate.\n",
        "\n",
        "The quality and representativeness of training sets have a significant impact on model performance. Well-selected data is essential for creating robust and accurate models. Changes to these sets can drastically affect the model's ability to generalize and make correct predictions on new data.\n",
        "\n",
        "Furthermore, the choice of hyperparameters is vital to the performance of the model. Poorly tuned hyperparameters can result in overfitting or underfitting, leading to low accuracy. Therefore, careful tuning and iterative testing of different hyperparameter settings are necessary to optimize the performance of machine learning models.\n",
        "\n",
        "Therefore, the use of various machine learning algorithms to detect breast cancer can save lives, increasing the accuracy and speed of diagnoses. Proper selection of datasets and accurate tuning of hyperparameters are essential steps to ensure models are effective and reliable"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "jmNc78hSol55",
        "Ll_DECXin-wY",
        "fsb1EQKTw4tZ",
        "-Ce-9EgCdfD0",
        "DRLyWFjmdWMF",
        "BMLexv6dbNWc",
        "842l6SWDo3oA"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
